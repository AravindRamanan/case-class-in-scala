CASE CLASSES ARE USED TO INFER SCHEMA
 
INPUT FILE FORMAT:

Barack,Obama,53
George,Bush,68
Bill,Clinton,68 
 
STEP 1: READING THE FILE FROM LOCAL AS AN RDD
 
scala> val a = sc.textFile("file:///home/ramanana/spark/person.txt")
a: org.apache.spark.rdd.RDD[String] = file:///home/ramanana/spark/person.txt MapPartitionsRDD[1] at textFile at <console>:24
 
STEP 2: SPLITTING THE LINES BASED ON DELIMITER
 
scala> val b = a.map(line => line.split(","))
b: org.apache.spark.rdd.RDD[Array[String]] = MapPartitionsRDD[2] at map at <console>:25
 
 
STEP 3: DEFINING THE CASE CLASS
 
scala> case class Person (first_name:String,last_name:String,age:String)
defined class Person
 
STEP 4:
 
scala> val c = b.map( bb => Person(bb(0),bb(1),bb(2)))
c: org.apache.spark.rdd.RDD[Person] = MapPartitionsRDD[3] at map at <console>:27
 
STEP 5: CONVERTING RDD TO DF
 
scala> val d = c.toDF()
d: org.apache.spark.sql.DataFrame = [first_name: string, last_name: string ... 1 more field]
 
scala> d.show()
+----------+---------+---+
|first_name|last_name|age|
+----------+---------+---+
|    Barack|    Obama| 53|
|    George|     Bush| 68|
|      Bill|  Clinton| 68|
+----------+---------+---+
 
 
 
 
